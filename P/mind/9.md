---
layout: default
---

# Where Does Creativity Come From?
New ideas can be conceived when considering a higher-level, ambiguous system of consciousness, particularly in the context of heuristics, intuition, and insight as they relate to cognitive psychology. Lofty inquiries originating from profound intellectual pursuits can be viewed as manifestations of consciousness functioning as a mechanical mechanism. Yet, to fully regard human consciousness as solely rational seems lacking; similar to the difficulty in expressing artistic inspiration through clear, linguistic means, something inherently feels missing.
One piece of evidence for this limitation comes from heuristics, including biases that operate at the automatic processing level—much like Freud's notion of the unconscious. While heuristics can be efficient from an information-processing perspective, they do not necessarily lead to rational thinking. The presence of cognitive leaps or errors in intuitive judgment is due to the role heuristics play in the composition of intuition. However, human intuition—though difficult to precisely define—often proves surprisingly persuasive. Intuitions are frequently instantaneous leaps of thought or unconscious inferences derived from a priori knowledge or past experiences. In that sense, distinguishing intuition from insight is not always clear-cut. Yet, relying solely on intuition can leave something wanting. In some cases, intuitive thinking is insufficient for problems that require insight; it is typically the controlled processing corresponding to insight that becomes essential for effectively solving such problems.
In Wolfgang Köhler’s insight learning, a solution derived through insight is said to be retained in memory even after just one occurrence. Here, insight refers to solutions that emerge suddenly from an understanding of the problem in its entirety. A representative example where insight is essential might involve physical reasoning. To illustrate with a mundane issue related to intuition, some people might simply end up daydreaming or lying down to rest when presented with a problem; these individuals can be seen as having failed to achieve insight learning for the proposed problem. On the other hand, there are those who strain their minds and solve an old, worn-out problem, and thus gain insight into it. In this context, I have come to believe that the essence of insight isn’t necessarily about whether or not one can solve the problem. Whether one gains insight through tackling the problem or by stepping away from it, we end up with some form of insight regardless.
When faced with a problem, we as humans will, in one way or another, develop an awareness of our actions. In My Perspective on the Relationship Between Creator and Creative Output, there was an assertion that at least for automatons, such meta-cognition is fundamentally impossible. Viewed in this way, it is quite striking that humans' metacognition appears largely independent of any specific knowledge they may or may not possess. Implementing human cognition, as represented by integrated information theory, is an extraordinarily complex endeavor. To replicate the architecture of the human brain's neural network using a machine that follows the von Neumann architecture would require an information-processing system entangled across several levels. Such a setup may involve constructing the machine’s operating system in a way that closely resembles the neural networks of the human brain.
However, it seems that even the most advanced artificial intelligence, regardless of how well it predicts outcomes in a game, cannot quite match the intricacies of human intelligence and the mysterious interplay between knowledge and ignorance—a balance often compared to walking a tightrope. If it were possible to implement a mechanism that resembles the human brain, at what point would we say an AI programmed as a system of possibilities—capable of exhibiting behaviors emerging from rules amidst mixed outcomes—is *thinking for itself*? When does AI break away from being an HCI system, acting beyond the mere commands of humans, to genuinely possess consciousness? Is it even structurally possible to comprehend something beyond the *meta-* system that transcends itself? And if it is possible, how would it be achieved?
At this level, can humans also attain insights into another (*meta-*) system that transcends the human framework? If it is possible, then what of the next level (*meta-meta*)? And after that (*meta-meta-meta*)? And then, what about the level beyond that (*meta-meta-meta-meta-...*)? Where do the rules of cognitive insight originate?
I believe that understanding where consciousness comes from becomes particularly crucial in these contexts. If imperfection exists in systems designed to align with nature, does that imply a fundamental flaw in those systems themselves? If metacognition operates on intuition, should we conclude that human consciousness is fundamentally flawed? This speculation contains a significant paradox, one that is unlikely to be resolved anytime soon.


<div class="pagination">
  <a href="{{ 'P/mind/mind_content.html' | relative_url }}" class="prev-button">Previous</a>
</div>
